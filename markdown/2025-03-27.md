了解しました。日本時間で昨日の AM9:00 から今日の AM9:00 までに公開された、AI/データサイエンス分野に関する最新の GitHub トレンド（Python）、論文（arXiv および Papers with Code）、企業ブログのニュース（指定企業）、および Zenn・Qiita・note で話題の記事を調査し、各セクションごとに日本語の要約と URL を含めた Markdown 形式の HTML レポートを作成します。

調査が完了し次第、結果をお届けします。しばらくお待ちください。

# 最新の AI/データサイエンス動向（日本時間 3 月 26 日 9:00〜3 月 27 日 9:00）

## 1. GitHub (Trending Repositories – Python, AI/Data Science 関連)

- **khoj-ai/khoj** – オンライン/ローカルの LLM を用いて、自分専用の「AI セカンドブレイン」を構築できる自己ホスト型プラットフォームです。Web やドキュメントから情報を取得して質問に回答したり、カスタムエージェントを作成してタスクの自動化や調査を行うことができます ([Trending Python repositories on GitHub today · GitHub](https://github.com/trending/python#:~:text=Your%20AI%20second%20brain.%20Self,free))。（GitHub: khoj-ai/khoj）
- **joanrod/star-vector** – SVG 画像を生成するためのファウンデーションモデル。視覚と言語の両モーダルを扱うアーキテクチャにより、画像とテキストから高品質な SVG コードを精密に生成します ([Trending Python repositories on GitHub today · GitHub](https://github.com/trending/python#:~:text=StarVector%20is%20a%20foundation%20model,SVG%20code%20with%20remarkable%20precision))。（GitHub: joanrod/star-vector）
- **deepseek-ai/DeepSeek-V3** – 総パラメータ数 6710 億（MoE により一度に 370 億を活性化）の超大規模言語モデル。Multi-head Latent Attention や独自 MoE アーキテクチャを採用し、既存のオープンソースモデルを上回る精度を達成、Claude 3.5 や GPT-4 といった閉源モデルに迫る性能を示しています ([DeepSeek V3: The best Open-source LLM | by Mehul Gupta | Data Science in your pocket | Medium](https://medium.com/data-science-in-your-pocket/deepseek-v3-the-best-open-source-llm-727d3421ae38#:~:text=ratio%20and%20accuracy%20,Here%E2%80%99s%20why%20it%E2%80%99s%20the%20best))。（GitHub: deepseek-ai/DeepSeek-V3）
- **browser-use/browser-use** – AI エージェントによる Web サイトの利用を可能にするブラウザ自動操作フレームワークです。ブラウザ操作を抽象化し、LLM エージェントが Web 上の情報を取得・操作できる環境を提供します ([Trending Python repositories on GitHub today · GitHub](https://github.com/trending/python#:~:text=Make%20websites%20accessible%20for%20AI,agents))。（GitHub: browser-use/browser-use）
- **vllm-project/vllm** – 大規模言語モデル向けの**高速**かつ**低メモリ消費**の推論・サ erving エンジン。独自のメモリ管理と実行最適化により、高スループットで効率的な LLM 推論を実現します ([Trending Python repositories on GitHub today · GitHub](https://github.com/trending/python#:~:text=A%20high,and%20serving%20engine%20for%20LLMs))。（GitHub: vllm-project/vllm）
- **agno-agi/agno** – マルチモーダルな AI エージェントを構築するための軽量ライブラリ。LLM を統一的な API で扱い、エージェントに長期記憶、知識ベース、ツール使用、推論能力などの「スーパーパワー」を付与できます ([Trending Python repositories on GitHub today · GitHub](https://github.com/trending/python#:~:text=Agno%20is%20a%20lightweight%20library,memory%2C%20knowledge%2C%20tools%20and%20reasoning))。（GitHub: agno-agi/agno）

## 2. 論文（最新の注目 AI/データサイエンス論文）

- **Long-Context Autoregressive Video Modeling with Next-Frame Prediction** – 長い時間文脈を扱うビデオ生成モデルに関する論文。言語モデルで成功している長文脈処理を動画領域に応用し、フレーム単位の自己回帰モデル「FAR」を提案しています。RoPE 位置エンコーディングに時間減衰を持たせた*FlexRoPE*や、短期高解像度コンテキスト＋長期低解像度コンテキストを組み合わせる手法で、長い動画に対する推論精度と速度を向上。短尺・長尺双方の動画生成で従来手法を上回る性能を達成しました ([Long-Context Autoregressive Video Modeling with Next-Frame Prediction](https://arxiv.org/html/2503.19325v1#:~:text=Long,Existing%20RoPE%20lacks%20effective)) ([Long-Context Autoregressive Video Modeling with Next-Frame Prediction](https://arxiv.org/html/2503.19325v1#:~:text=as%20vision%20tokens%20grow%20much,and))。（2025/3/26 公開、NUS Show Lab 他）
- **Qwen2.5-Omni-7B (Alibaba Cloud)** – アリババクラウドが発表した**エッジデバイス向け**の小型マルチモーダル AI モデルです。テキスト・画像・音声・動画を統合的に扱い、入力に対するリアルタイムのテキスト応答や音声応答を生成可能。わずか 70 億パラメータながら、音声対話や画像・音声・テキストを組み合わせた推論（OmniBench）で最先端の性能を示し、音声対話の品質では新たなベンチマークを樹立したと報告されています ([Alibaba Cloud Releases Qwen2.5-Omni-7B](https://www.alizila.com/alibaba-cloud-releases-qwen2-5-omni-7b-an-end-to-end-multimodal-ai-model/#:~:text=Alibaba%20Cloud%20has%20launched%C2%A0Qwen2.5,devices%20like%C2%A0mobile%20phones%20and%20laptops)) ([Alibaba Cloud Releases Qwen2.5-Omni-7B](https://www.alizila.com/alibaba-cloud-releases-qwen2-5-omni-7b-an-end-to-end-multimodal-ai-model/#:~:text=High%20Performance%20Driven%20by%20Innovative,Architecture))。（2025/3/27 発表、モデルはオープンソース ([Alibaba Cloud Releases Qwen2.5-Omni-7B](https://www.alizila.com/alibaba-cloud-releases-qwen2-5-omni-7b-an-end-to-end-multimodal-ai-model/#:~:text=The%20model%20is%20now%C2%A0open,source))）
- **DeepSeek-V3 Technical Report** – 中国発の超大規模 LLM「DeepSeek-V3」の技術報告。Mixture-of-Experts 構造による**6710 億パラメータ**のモデルで、一度に 370 億パラメータのみを活性化することで効率化を図っています。14.8 兆トークンでの事前学習と指導・強化学習を経て、MMLU など知識タスクで 90 点近くを記録し、Claude 3.5 や GPT-4 といった閉源モデルに肉薄する最高水準の性能を達成しました ([DeepSeek V3: The best Open-source LLM | by Mehul Gupta | Data Science in your pocket | Medium](https://medium.com/data-science-in-your-pocket/deepseek-v3-the-best-open-source-llm-727d3421ae38#:~:text=ratio%20and%20accuracy%20,Here%E2%80%99s%20why%20it%E2%80%99s%20the%20best)) ([DeepSeek V3: The best Open-source LLM | by Mehul Gupta | Data Science in your pocket | Medium](https://medium.com/data-science-in-your-pocket/deepseek-v3-the-best-open-source-llm-727d3421ae38#:~:text=Model%20Size%20and%20Efficiency%3A))。（2024/12 公開の論文、2025/3 にコードとモデル公開）
- **長文ビデオ生成における位置エンコーディングの改良** – 上記 FAR モデルに関連し、既存の RoPE エンコーディングが長い動画文脈に不適応な点を指摘し、時間減衰性を持たせた**FlexRoPE**を導入することで長時間の動画シーケンス外挿性を向上させています ([Long-Context Autoregressive Video Modeling with Next-Frame Prediction](https://arxiv.org/html/2503.19325v1#:~:text=transformers,term%20context%20window%20ensures))。また、高解像度の短期コンテキストと無制限の長期コンテキストを組み合わせて学習することで、計算コストを抑えつつ長尺動画に対応しています ([Long-Context Autoregressive Video Modeling with Next-Frame Prediction](https://arxiv.org/html/2503.19325v1#:~:text=as%20vision%20tokens%20grow%20much,and))。（FAR 論文に含まれる提案手法）  
  ＊※その他、**Attention IoU によるモデルバイアス解析（CelebA データセット）**や**多クラス異常検知のための Diffusion モデル改良**などの最新論文もこの期間に公開されています ([Latest papers with code | Papers With Code](https://paperswithcode.com/latest#:~:text=Correcting%20Deviations%20from%20Normality%3A%20A,Class%20Unsupervised%20Anomaly%20Detection)) ([Latest papers with code | Papers With Code](https://paperswithcode.com/latest#:~:text=Attention%20IoU%3A%20Examining%20Biases%20in,CelebA%20using%20Attention%20Maps))。

## 3. 企業ブログ（ニュース・アップデート）

- **OpenAI** – セキュリティと AI 開発に関する最新動向をまとめたブログ記事を公開しました。「AGI への道のりにおけるセキュリティ」と題し、過去 2 年間で 28 件の研究プロジェクトに助成してきた**サイバーセキュリティ助成プログラム**の成果を紹介するとともに、今後は脆弱性検知・自動パッチ適用など幅広いテーマで提案を募るとしています ([Security on the path to AGI | OpenAI](https://openai.com/index/security-on-the-path-to-agi/#:~:text=Evolving%20our%20Cybersecurity%20Grant%20Program,like%20prompt%20injection%2C%20secure%20code)) ([Security on the path to AGI | OpenAI](https://openai.com/index/security-on-the-path-to-agi/#:~:text=The%20Cybersecurity%20Grant%20Program%20is,for%20new%20grant%20applications%20include))。また**バグバウンティ**の拡充など安全性向上策にも言及しています。
- **OpenAI (プロダクト)** – CEO の Sam Altman 氏は、他社 Anthropic が提唱するオープン標準**「モデルコンテキストプロトコル（MCP）」**を自社製品群に採用すると発表しました。MCP は外部の業務データやツールと AI アシスタントを連携させるためのオープンプロトコルで、ChatGPT デスクトップ版や Agent SDK に対応が進められます ([OpenAI adopts rival Anthropic's standard for connecting AI models to data | TechCrunch](https://techcrunch.com/2025/03/26/openai-adopts-rival-anthropics-standard-for-connecting-ai-models-to-data/#:~:text=OpenAI%20is%20embracing%20rival%20Anthropic%E2%80%99s,the%20systems%20where%20data%20resides)) ([OpenAI adopts rival Anthropic's standard for connecting AI models to data | TechCrunch](https://techcrunch.com/2025/03/26/openai-adopts-rival-anthropics-standard-for-connecting-ai-models-to-data/#:~:text=MCP%20lets%20models%20draw%20data,powered%20applications%2C%20such%20as%20chatbots))。Anthropic の CPO も「OpenAI が MCP に対応するのを歓迎する」とコメントしており、サードパーティ各社を含め急速に普及が進んでいます ([OpenAI adopts rival Anthropic's standard for connecting AI models to data | TechCrunch](https://techcrunch.com/2025/03/26/openai-adopts-rival-anthropics-standard-for-connecting-ai-models-to-data/#:~:text=Developers%20can%20expose%20data%20through,MCP%20support%20for%20their%20platforms))。
- **Google/DeepMind** – **「Gemini 2.5」**を発表しました。思考過程をシミュレートする**“Thinking Model”**と位置づけられた新モデルで、推論能力やコード生成能力が強化されています。最上位の**Gemini 2.5 Pro Experimental**は多数のベンチマークで従来モデルを大きく上回り、オープン評価サイトの LMArena で現時点トップに立ったとされています ([Gemini 2.5: Our newest Gemini model with thinking](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/#:~:text=Gemini%202,strong%20reasoning%20and%20code%20capabilities)) ([Gemini 2.5: Our newest Gemini model with thinking](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/#:~:text=Today%20we%E2%80%99re%20introducing%20Gemini%202,LMArena%20by%20a%20significant%20margin))。このモデルは応答を生成する前に内部で推論ステップを踏む「考える AI」であり、より高い正確性と論理的整合性を実現したとのことです。
- **Google (Workspace)** – Google は同日、ビデオ会議サービス Meet 向けの新機能群も発表しました。AI アシスタント**「Gemini」**を活用した要約機能強化で、**議事録の自動要約にアクションアイテム（ToDo）を抽出追加**する機能や、会議トランスクリプトと要約をリンクさせて発言詳細を容易に確認できる機能、会議中にリアルタイムで字幕履歴をスクロール閲覧できる機能などが追加されています ([New Gemini features launch for Google Meet](https://blog.google/products/workspace/workspace-feature-drop-gemini-google-meet/#:~:text=1,while%20the%20meeting%20is%20happening))。
- **Anthropic** – (新規発表はありませんが、)**モデルコンテキストプロトコル（MCP）**が OpenAI に採用されるなど、自社提唱の標準が業界に波及する動きがありました。また Anthropic は先週、対話型 AI「Claude」に**インターネット検索機能**を追加するアップデートを実施しており、最新情報を引用付きで回答できるようになっています ([Claude can now search the web \ Anthropic](https://www.anthropic.com/news/web-search#:~:text=You%20can%20now%20use%20Claude,from%20the%20most%20recent%20data))（現在プレビュー版として米国の Claude ユーザに提供中）。
- **Meta** – 目立った公式発表はありませんでしたが、業界報道によれば**自社開発の AI チップ**のテストを開始するなど AI インフラ整備を加速している模様です ([Exclusive: Meta begins testing its first in-house AI training chip | Reuters](https://www.reuters.com/technology/artificial-intelligence/meta-begins-testing-its-first-in-house-ai-training-chip-2025-03-11/#:~:text=NEW%20YORK%2C%20March%2011%20,98%2C%20two%20sources%20told%20Reuters))（3 月 11 日付 Reuters）。一方で、オープンソースコミュニティでは Meta の大規模モデル Llama 系の派生・活用が引き続き活発に行われています。
- **Alibaba (アリババ)** – 上述の**Qwen2.5-Omni-7B**モデルを公式ブログで発表しました ([Alibaba Cloud Releases Qwen2.5-Omni-7B](https://www.alizila.com/alibaba-cloud-releases-qwen2-5-omni-7b-an-end-to-end-multimodal-ai-model/#:~:text=Alibaba%20Cloud%20has%20launched%C2%A0Qwen2.5,devices%20like%C2%A0mobile%20phones%20and%20laptops))。わずか 70 億規模ながらテキスト・画像・音声・動画のマルチモーダルを統合し、**スマホ等でも動作可能**な軽量さと高性能を両立した点が強調されています ([Alibaba Cloud Releases Qwen2.5-Omni-7B](https://www.alizila.com/alibaba-cloud-releases-qwen2-5-omni-7b-an-end-to-end-multimodal-ai-model/#:~:text=perception%2C%20it%20can%20process%20diverse,devices%20like%C2%A0mobile%20phones%20and%20laptops)) ([Alibaba Cloud Releases Qwen2.5-Omni-7B](https://www.alizila.com/alibaba-cloud-releases-qwen2-5-omni-7b-an-end-to-end-multimodal-ai-model/#:~:text=Qwen2.5,end%20speech%20instruction%20following))。同社は 2 ヶ月前にも大規模モデル**Qwen2.5-Max**をリリースしており、こちらは DeepSeek-V3 や Llama3.1-405B など他社最新モデルをベンチマークで上回るとアピールしていました ([Alibaba Cloud Launches Compact, Multimodal AI Model](https://www.pymnts.com/artificial-intelligence-2/2025/alibaba-cloud-launches-compact-multimodal-ai-model/#:~:text=This%20announcement%20came%20about%20two,AI%20models%20on%20key%20benchmarks))。
- **Hugging Face** – 特定の新製品発表はありませんが、Hugging Face 上に**DeepSeek-V3**のモデルが 3 月 25 日に公開され、大きな注目を集めました（中国・北京からサプライズ公開） ([DeepSeek-V3-0324 Quietly Lands on Hugging Face - HPCwire](https://www.hpcwire.com/off-the-wire/deepseek-v3-0324-quietly-lands-on-hugging-face/#:~:text=DeepSeek,quietly%20dropped%20on%20Hugging%20Face))。また、NVIDIA が同社プラットフォーム上で**4K 解像度対応の画像生成モデル**を公開するなど ([AK on X: "Nvidia just announced Scaling Vision Pre-Training to 4K ...](https://twitter.com/_akhaliq/status/1904885572868469167#:~:text=AK%20on%20X%3A%20,PM%20%C2%B7%20Mar%2026%2C%202025))、引き続き HF は最新モデル共有のハブとなっています。
  _(その他、Microsoft、Apple、Vercel、Devin、Ollama、DeepSeek, Manus, Baidu, ByteDance については、当該期間に特筆すべき公式ブログ更新は確認されませんでした。)_

## 4. ブログ記事（個人・コミュニティ発信の話題）

- **ChatGPT『GPT-4o』画像生成機能の大幅アップデート** – 3 月 26 日に OpenAI が ChatGPT の画像生成能力を強化し、順次ユーザーへ提供を開始しました。これにより ChatGPT 上で**4 コマ漫画風の画像**を生成したり、ユーザーが指定したスタイル（ジブリ風・ディズニー風など）で画像を出力することが可能になっています ([ChatGPT『GPT-4o』画像生成が大幅アップデート！](https://zenn.dev/nouchinho/articles/35f2a93464f0d9#:~:text=1.%20GPT,Team%2C%20%E3%81%9D%E3%81%97%E3%81%A6Free%E3%83%97%E3%83%A9%E3%83%B3%E3%81%AE%E3%83%A6%E3%83%BC%E3%82%B6%E3%83%BC%E3%81%AB%E3%81%AF%E3%80%81%E3%83%87%E3%83%95%E3%82%A9%E3%83%AB%E3%83%88%E3%81%AE%E7%94%BB%E5%83%8F%E7%94%9F%E6%88%90%E6%A9%9F%E8%83%BD%E3%81%A8%E3%81%97%E3%81%A6%E6%AE%B5%E9%9A%8E%E7%9A%84%E3%81%AB%E5%B1%95%E9%96%8B%E3%81%95%E3%82%8C%E3%81%BE%E3%81%99%E3%80%82Enterprise%20%E3%81%8A%E3%82%88%E3%81%B3%20Edu%20%E3%83%97%E3%83%A9%E3%83%B3%E3%81%AE%E3%83%A6%E3%83%BC%E3%82%B6%E3%83%BC%E3%81%B8%E3%81%AE%E6%8F%90%E4%BE%9B%E3%81%AF%E3%80%81%E8%BF%91%E6%97%A5%E4%B8%AD%E3%81%AB%E9%96%8B%E5%A7%8B%E3%81%95%E3%82%8C%E3%82%8B%E4%BA%88%E5%AE%9A%E3%81%A7%E3%81%99%E3%80%82))。実際に新機能を試したユーザーブログでは、赤ちゃんの成長物語を 4 コマ漫画化するプロンプトなどを例示し、その表現力向上を報告しています ([ChatGPT『GPT-4o』画像生成が大幅アップデート！](https://zenn.dev/nouchinho/articles/35f2a93464f0d9#:~:text=1,%E3%83%97%E3%83%AD%E3%83%B3%E3%83%97%E3%83%88%EF%BC%9A2%E4%BA%BA%E3%81%AE%E5%86%99%E7%9C%9F%E3%82%92%E5%8F%82%E8%80%83%E3%81%AB%E9%99%90%E3%82%8A%E3%81%AA%E3%81%8F%E3%82%B9%E3%83%8C%E3%83%BC%E3%83%94%E3%83%BC%E3%81%AB%E5%AF%84%E3%81%9B%E3%81%9F%E7%94%BB%E5%83%8F%E3%82%92%E7%94%9F%E6%88%90%E3%81%97%E3%81%A6%20Image))。
- **開発系 AI エージェントサービスの賢い課金法** – 複数の AI コーディング支援ツールに年間課金してきたエンジニアが、自身の経験から最適な課金先を考察した記事です。「Cursor」「Claude 3.7 Sonnet」「Windsurf」「Cline」「Devin」「Dify」等の開発エージェントが乱立する現状で、**結論は「月額課金の Cursor 一択」**と断言しています ([複数の年間課金をして分かった開発 AI エージェントの課金しどころ](https://zenn.dev/tkwbr999/articles/49eb9cc5217b7f#:~:text=TL%3BDR))。理由は「年契約しても数ヶ月で新しく優れた選択肢が登場し後悔する」ためで、まずは各種ツールの無料トライアルを活用しつつ、必要に応じて月額で柔軟に乗り換えることを推奨しています ([複数の年間課金をして分かった開発 AI エージェントの課金しどころ](https://zenn.dev/tkwbr999/articles/49eb9cc5217b7f#:~:text=%E4%B8%89%E3%83%B6%E6%9C%88%E3%81%8F%E3%82%89%E3%81%84%E5%89%8D%E3%81%BE%E3%81%A7%E3%81%AF%E3%81%93%E3%82%93%E3%81%AA%E3%81%AB%E6%83%85%E5%A0%B1%E3%81%8C%E5%87%BA%E5%9B%9E%E3%81%A3%E3%81%A6%E3%81%AA%E3%81%8B%E3%81%A3%E3%81%9F%E3%81%A8%E6%80%9D%E3%81%86%E3%81%AE%E3%81%A7%E3%81%99%E3%81%8C%E3%80%81%E6%9C%80%E8%BF%91%E3%81%AF%E4%B8%BB%E3%81%ABclaude3)) ([複数の年間課金をして分かった開発 AI エージェントの課金しどころ](https://zenn.dev/tkwbr999/articles/49eb9cc5217b7f#:~:text=%E5%83%95%E3%81%AF%E3%81%9D%E3%81%AE%E6%99%82%E3%80%85%E3%81%A7%E4%B8%80%E7%95%AA%E8%89%AF%E3%81%95%E3%81%9D%E3%81%86%E3%81%AA%E3%82%82%E3%81%AE%E3%81%AB%E5%B9%B4%E9%96%93%E8%AA%B2%E9%87%91%E3%81%97%E3%81%A6%E3%81%84%E3%81%9F%E3%81%AE%E3%81%A7%E3%81%99%E3%81%8C%E3%80%81%E6%95%B0%E3%83%B6%E6%9C%88%E3%81%A7%E5%88%A5%E3%81%AE%E3%82%88%E3%82%8A%E3%82%88%E3%81%84%E9%81%B8%E6%8A%9E%E8%82%A2%E3%81%8C%E7%99%BB%E5%A0%B4%E3%81%97%E3%81%A6%E3%81%8F%E3%82%8B%E3%81%AE%E3%81%A7%E5%B9%B4%E9%96%93%E8%AA%B2%E9%87%91%E3%81%AA%E3%82%93%E3%81%A6%E3%81%97%E3%81%AA%E3%81%8D%E3%82%83%E3%82%88%E3%81%8B%E3%81%A3%E3%81%9F%E3%83%BB%E3%83%BB%E3%83%BB%E3%81%BF%E3%81%9F%E3%81%84%E3%81%AA%E6%B0%97%E6%8C%81%E3%81%A1%E3%81%AB%E3%81%AA%E3%81%A3%20%E3%81%A6%E3%81%BE%E3%81%99%E3%80%82))。
- **「AI があるんだからもっと安く早く作れるでしょ？」への回答** – Qiita に投稿されたある記事は、非エンジニアから無邪気にこう言われた際にエンジニアが読むべき（または相手に読ませたい）内容として大反響を呼びました。記事では「確かに**AI で 30 秒もあれば簡単なプログラムは生成できる**」としながらも、実際の企業向けソフト開発では AI はしばしば誤ったコードを出力したり既存コードを壊したりするため、「**現実の開発には人間と同様の手間がかかる**」ことをユーモアを交えて解説しています ([「AI があるんだからもっと安く早く作れるでしょ？」と非エンジニアに言われた時に読む（読んでもらう）記事 #ビジネス - Qiita](https://qiita.com/ku_suke/items/577bdb839b411fe75e44#:~:text=Last%20updated%20at%202025,13)) ([「AI があるんだからもっと安く早く作れるでしょ？」と非エンジニアに言われた時に読む（読んでもらう）記事 #ビジネス - Qiita](https://qiita.com/ku_suke/items/577bdb839b411fe75e44#:~:text=%E3%80%8C%E3%81%84%E3%81%BE%E3%81%A3%E3%81%A6AI%E3%81%8C%E3%81%82%E3%82%8B%E3%81%8B%E3%82%89%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E3%81%AA%E3%82%93%E3%81%A6%E4%B8%80%E7%9E%AC%E3%81%A7%E3%81%A7%E3%81%8D%E3%81%A1%E3%82%83%E3%81%86%E3%82%93%E3%81%A7%E3%81%97%E3%82%87%EF%BC%9F%E3%81%86%E3%81%A1%E3%81%AE%E3%82%82%E3%82%82%E3%81%A3%E3%81%A8%E5%AE%89%E3%81%8F%E6%97%A9%E3%81%8F%E3%81%A7%E3%81%8D%E3%81%AA%E3%81%84%E3%81%AE%EF%BC%9F%E3%80%8D%E3%81%A8%E7%84%A1%E9%82%AA%E6%B0%97%E3%81%AA%E9%9D%9E%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%AB%E8%A8%80%E3%82%8F%E3%82%8C%E3%81%9F%E7%B5%8C%E9%A8%93%E3%81%8C%E3%81%82%E3%82%8B%E3%82%BD%E3%83%95%E3%83%88%E3%82%A6%E3%82%A8%E3%82%A2%20%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%AE%E7%9A%86%E3%81%95%E3%82%93%E3%82%84%E3%80%81%E3%81%9D%E3%82%8C%E3%81%AB%E5%AF%BE%E3%81%97%E3%81%A6%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%8B%E3%82%89%E5%BE%AE%E5%A6%99%E3%81%AA%E8%A1%A8%E6%83%85%E3%81%A7%E5%BE%AE%E5%A6%99%E3%81%AA%E8%BF%94%E4%BA%8B%E3%82%92%E3%81%95%E3%82%8C%E3%81%9F%E3%83%93%E3%82%B8%E3%83%8D%E3%82%B9%E8%81%B7%E3%81%AE%E7%9A%86%E3%81%95%E3%82%93%E3%81%AB%E5%90%91%E3%81%91%E3%81%A6%E8%A8%98%E4%BA%8B%E3%82%92%E6%9B%B8%E3%81%8D%E3%81%BE%E3%81%97%E3%81%9F%E3%80%82%E3%81%AA%E3%81%8A%E3%81%93%E3%81%AE%E8%A8%98%E4%BA%8B%E3%81%AE%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E3%81%AF100%EF%BC%85%E4%BA%BA%E9%96%93%E3%81%AE%20%E6%89%8B%E3%81%AB%E3%82%88%E3%81%A3%E3%81%A6%E6%9B%B8%E3%81%8B%E3%82%8C%E3%81%A6%E3%81%84%E3%81%BE%E3%81%99%E3%80%82))。この投稿は 800 件以上の「いいね」を集め、3 月の Qiita 上でトップクラスの人気記事となっています。
- **「Tableau LangChain」を試してみた** – Tableau のデータソースに自然言語で質問できる OSS ツール「tableau_langchain」を検証した技術ブログ記事です。LangChain や Pinecone、Tavily など複数の LLM 関連サービスを組み合わせ、**Tableau Cloud 上のデータに対して会話的にクエリを投げる**仕組みを構築しています ([Tableau のデータに対して生成 AI を利用して質問ができる「Tableau Langchain」を試してみた](https://zenn.dev/cavernaria/articles/ef88238ff090e4#:~:text=%E3%81%9D%E3%82%82%E3%81%9D%E3%82%82%E3%81%BE%E3%81%9ALangchain%E3%81%A8%E3%81%AF%E3%81%AA%E3%82%93%E3%82%84%E3%81%AD%E3%82%93%E3%81%A3%E3%81%A6%E3%81%84%E3%81%86%E8%A9%B1%E3%81%A7%E3%81%99%E3%81%8C%E3%80%81%E4%BB%A5%E4%B8%8B%E3%81%AB%E3%82%88%E3%82%8C%E3%81%B0%E3%80%8CChatGPT%E3%81%AA%E3%81%A9%E3%81%AE%E5%A4%A7%E8%A6%8F%E6%A8%A1%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%A9%9F%E8%83%BD%E6%8B%A1%E5%BC%B5%E3%82%92%E5%8A%B9%E7%8E%87%E7%9A%84%E3%81%AB%E5%AE%9F%E8%A3%85%E3%81%99%E3%82%8B%E3%81%9F%E3%82%81%E3%81%AE%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%80%8D%E3%81%A0%20%E3%81%9D%E3%81%86%E3%81%A7%E3%81%99%E3%80%82))。記事ではセットアップ手順から実際の Q&A 例までを紹介し、非エンジニアでも BI データを対話的に活用できる可能性に言及しています。
- **その他の話題**: Zenn では「Gemini-2.5 のベンチマーク未公開の理由を推測する記事」や「生成 AI を用いた類似文書検索の実装と課題分析」などが公開され、note では有志による**週間 AI ニュースまとめ**や、企業の生成 AI 活用事例のレポート等が発信されています ([いち早く生成系 AI 機能をリリースした note が目指す - ProductZine](https://productzine.jp/article/detail/2083#:~:text=%E3%81%84%E3%81%A1%E6%97%A9%E3%81%8F%E7%94%9F%E6%88%90%E7%B3%BBAI%E6%A9%9F%E8%83%BD%E3%82%92%E3%83%AA%E3%83%AA%E3%83%BC%E3%82%B9%E3%81%97%E3%81%9Fnote%E3%81%8C%E7%9B%AE%E6%8C%87%E3%81%99%20,)) ([【厳選 7 ツール】研究効率が劇的に変わる！2025 年おすすめ AI ツール](https://www.academianote.site/ai-summary/#:~:text=%E5%8E%B3%E9%81%B87%E3%83%84%E3%83%BC%E3%83%AB%20%E7%A0%94%E7%A9%B6%E5%8A%B9%E7%8E%87%E3%81%8C%E5%8A%87%E7%9A%84%E3%81%AB%E5%A4%89%E3%82%8F%E3%82%8B%EF%BC%812025%E5%B9%B4%E3%81%8A%E3%81%99%E3%81%99%E3%82%81AI%E3%83%84%E3%83%BC%E3%83%AB%20%E3%81%93%E3%81%AE%E8%A8%98%E4%BA%8B%E3%81%A7%E3%81%AF%E7%A0%94%E7%A9%B6%E3%82%92%E9%AB%98%E9%80%9F%E5%8C%96%E3%81%99%E3%82%8BAI%E3%83%84%E3%83%BC%E3%83%AB7%E9%81%B8%E3%82%92%E3%81%94%E7%B4%B9%E4%BB%8B%E3%81%97%E3%81%BE%E3%81%99%E3%80%82%20%E7%8F%BE%E5%9C%A8%E3%81%A7%E3%81%AF%E3%81%95%E3%81%BE%E3%81%96%E3%81%BE%E3%81%AA%E7%A0%94%E7%A9%B6%E8%80%85%E5%90%91%E3%81%91%E3%81%AEAI%E3%83%84%E3%83%BC%E3%83%AB%E3%81%8C%E7%99%BB%E5%A0%B4%E3%81%97%E3%81%A6%E3%81%84%E3%81%BE%E3%81%99%E3%80%82%20AI%E3%83%84%E3%83%BC%E3%83%AB%E3%82%92%E4%BD%BF%E3%81%86%E3%83%A1%E3%83%AA%E3%83%83%E3%83%88))。

([Trending Python repositories on GitHub today · GitHub](https://github.com/trending/python#:~:text=Your%20AI%20second%20brain.%20Self,free)) ([Trending Python repositories on GitHub today · GitHub](https://github.com/trending/python#:~:text=StarVector%20is%20a%20foundation%20model,SVG%20code%20with%20remarkable%20precision)) ([DeepSeek V3: The best Open-source LLM | by Mehul Gupta | Data Science in your pocket | Medium](https://medium.com/data-science-in-your-pocket/deepseek-v3-the-best-open-source-llm-727d3421ae38#:~:text=ratio%20and%20accuracy%20,Here%E2%80%99s%20why%20it%E2%80%99s%20the%20best)) ([Trending Python repositories on GitHub today · GitHub](https://github.com/trending/python#:~:text=Make%20websites%20accessible%20for%20AI,agents)) ([Trending Python repositories on GitHub today · GitHub](https://github.com/trending/python#:~:text=A%20high,and%20serving%20engine%20for%20LLMs)) ([Trending Python repositories on GitHub today · GitHub](https://github.com/trending/python#:~:text=Agno%20is%20a%20lightweight%20library,memory%2C%20knowledge%2C%20tools%20and%20reasoning))

([Long-Context Autoregressive Video Modeling with Next-Frame Prediction](https://arxiv.org/html/2503.19325v1#:~:text=transformers,term%20context%20window%20ensures)) ([Long-Context Autoregressive Video Modeling with Next-Frame Prediction](https://arxiv.org/html/2503.19325v1#:~:text=as%20vision%20tokens%20grow%20much,and)) ([Alibaba Cloud Releases Qwen2.5-Omni-7B](https://www.alizila.com/alibaba-cloud-releases-qwen2-5-omni-7b-an-end-to-end-multimodal-ai-model/#:~:text=Alibaba%20Cloud%20has%20launched%C2%A0Qwen2.5,devices%20like%C2%A0mobile%20phones%20and%20laptops)) ([Alibaba Cloud Releases Qwen2.5-Omni-7B](https://www.alizila.com/alibaba-cloud-releases-qwen2-5-omni-7b-an-end-to-end-multimodal-ai-model/#:~:text=Qwen2.5,end%20speech%20instruction%20following))

([Security on the path to AGI | OpenAI](https://openai.com/index/security-on-the-path-to-agi/#:~:text=Evolving%20our%20Cybersecurity%20Grant%20Program,like%20prompt%20injection%2C%20secure%20code)) ([OpenAI adopts rival Anthropic's standard for connecting AI models to data | TechCrunch](https://techcrunch.com/2025/03/26/openai-adopts-rival-anthropics-standard-for-connecting-ai-models-to-data/#:~:text=OpenAI%20is%20embracing%20rival%20Anthropic%E2%80%99s,the%20systems%20where%20data%20resides)) ([OpenAI adopts rival Anthropic's standard for connecting AI models to data | TechCrunch](https://techcrunch.com/2025/03/26/openai-adopts-rival-anthropics-standard-for-connecting-ai-models-to-data/#:~:text=Developers%20can%20expose%20data%20through,MCP%20support%20for%20their%20platforms))

([Gemini 2.5: Our newest Gemini model with thinking](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/#:~:text=Today%20we%E2%80%99re%20introducing%20Gemini%202,LMArena%20by%20a%20significant%20margin)) ([New Gemini features launch for Google Meet](https://blog.google/products/workspace/workspace-feature-drop-gemini-google-meet/#:~:text=1,while%20the%20meeting%20is%20happening)) ([Claude can now search the web \ Anthropic](https://www.anthropic.com/news/web-search#:~:text=You%20can%20now%20use%20Claude,from%20the%20most%20recent%20data))

([ChatGPT『GPT-4o』画像生成が大幅アップデート！](https://zenn.dev/nouchinho/articles/35f2a93464f0d9#:~:text=1.%20GPT,Team%2C%20%E3%81%9D%E3%81%97%E3%81%A6Free%E3%83%97%E3%83%A9%E3%83%B3%E3%81%AE%E3%83%A6%E3%83%BC%E3%82%B6%E3%83%BC%E3%81%AB%E3%81%AF%E3%80%81%E3%83%87%E3%83%95%E3%82%A9%E3%83%AB%E3%83%88%E3%81%AE%E7%94%BB%E5%83%8F%E7%94%9F%E6%88%90%E6%A9%9F%E8%83%BD%E3%81%A8%E3%81%97%E3%81%A6%E6%AE%B5%E9%9A%8E%E7%9A%84%E3%81%AB%E5%B1%95%E9%96%8B%E3%81%95%E3%82%8C%E3%81%BE%E3%81%99%E3%80%82Enterprise%20%E3%81%8A%E3%82%88%E3%81%B3%20Edu%20%E3%83%97%E3%83%A9%E3%83%B3%E3%81%AE%E3%83%A6%E3%83%BC%E3%82%B6%E3%83%BC%E3%81%B8%E3%81%AE%E6%8F%90%E4%BE%9B%E3%81%AF%E3%80%81%E8%BF%91%E6%97%A5%E4%B8%AD%E3%81%AB%E9%96%8B%E5%A7%8B%E3%81%95%E3%82%8C%E3%82%8B%E4%BA%88%E5%AE%9A%E3%81%A7%E3%81%99%E3%80%82)) ([複数の年間課金をして分かった開発 AI エージェントの課金しどころ](https://zenn.dev/tkwbr999/articles/49eb9cc5217b7f#:~:text=TL%3BDR))
